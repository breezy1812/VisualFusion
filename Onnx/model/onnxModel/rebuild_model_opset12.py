#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œå…¨é‡å»ºONNXæ¨¡å‹ï¼Œå¼·åˆ¶ä½¿ç”¨opset 12ï¼Œè§£æ±ºopset 23å…¼å®¹æ€§å•é¡Œ
"""

import onnx
from onnx import TensorProto, helper, numpy_helper
import os
import numpy as np

def rebuild_model_with_opset12():
    """å®Œå…¨é‡å»ºæ¨¡å‹ï¼Œå¼·åˆ¶ä½¿ç”¨opset 12"""
    
    print("ğŸ”§ å®Œå…¨é‡å»ºæ¨¡å‹ - å¼·åˆ¶ opset 12")
    print("=" * 60)
    
    fp16_file = './fp16.onnx'
    output_file = './SemLA_onnx_320x240_fp16_opset12.onnx'
    
    if not os.path.exists(fp16_file):
        print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {fp16_file}")
        return False
    
    try:
        # è¼‰å…¥åŸå§‹æ¨¡å‹
        print("ğŸ“ è¼‰å…¥åŸå§‹æ¨¡å‹...")
        original_model = onnx.load(fp16_file)
        original_graph = original_model.graph
        
        print(f"   åŸå§‹opsetç‰ˆæœ¬: {[f'{op.domain}:{op.version}' for op in original_model.opset_import]}")
        
        # æ”¶é›†æ‰€æœ‰å¿…è¦çµ„ä»¶
        print("ğŸ“¦ æ”¶é›†æ¨¡å‹çµ„ä»¶...")
        
        # 1. æ”¶é›†åˆå§‹åŒ–å™¨ï¼ˆæ¬Šé‡ï¼‰
        initializers = []
        for init in original_graph.initializer:
            initializers.append(init)
        
        print(f"   åˆå§‹åŒ–å™¨æ•¸é‡: {len(initializers)}")
        
        # 2. æ”¶é›†value_infoï¼ˆä¸­é–“å¼µé‡ä¿¡æ¯ï¼‰
        value_infos = []
        for vi in original_graph.value_info:
            value_infos.append(vi)
        
        print(f"   value_infoæ•¸é‡: {len(value_infos)}")
        
        # 3. æ”¶é›†ç¯€é»ï¼Œä¸¦ç¢ºä¿æ‰€æœ‰operatoréƒ½å…¼å®¹opset 12
        nodes = []
        incompatible_ops = []
        
        for node in original_graph.node:
            # æª¢æŸ¥æ˜¯å¦æœ‰opset 12ä¸æ”¯æ´çš„operator
            if node.op_type in ['CastLike', 'ScatterElements', 'GatherElements']:
                print(f"   âš ï¸  ç™¼ç¾å¯èƒ½ä¸å…¼å®¹çš„operator: {node.op_type}")
                incompatible_ops.append(node.op_type)
            
            nodes.append(node)
        
        print(f"   ç¯€é»æ•¸é‡: {len(nodes)}")
        if incompatible_ops:
            print(f"   å¯èƒ½ä¸å…¼å®¹çš„æ“ä½œ: {set(incompatible_ops)}")
        
        # 4. é‡æ–°å‰µå»ºè¼¸å…¥
        inputs = []
        for inp in original_graph.input:
            inputs.append(inp)
        
        # 5. é‡æ–°å‰µå»ºè¼¸å‡º
        outputs = []
        for out in original_graph.output:
            outputs.append(out)
        
        print("ğŸ—ï¸  é‡å»ºåœ–å½¢...")
        
        # å‰µå»ºæ–°åœ–å½¢
        new_graph = helper.make_graph(
            nodes=nodes,
            name=original_graph.name + "_opset12",
            inputs=inputs,
            outputs=outputs,
            initializer=initializers,
            value_info=value_infos
        )
        
        # å¼·åˆ¶è¨­ç½®opset 12
        opset_imports = [
            helper.make_opsetid("", 17)  # ä¸»è¦opsetè¨­ç‚º12
        ]
        
        print("ğŸ“¦ é‡å»ºæ¨¡å‹...")
        
        # å‰µå»ºæ–°æ¨¡å‹
        new_model = helper.make_model(
            new_graph, 
            opset_imports=opset_imports,
            producer_name="rebuilt_opset12",
            producer_version="1.0"
        )
        
        # è¨­ç½®å…ƒæ•¸æ“š
        if original_model.model_version:
            new_model.model_version = original_model.model_version
        
        print("ğŸ” æª¢æŸ¥æ¨¡å‹...")
        
        # æª¢æŸ¥æ¨¡å‹
        try:
            onnx.checker.check_model(new_model)
            print("âœ… æ¨¡å‹æª¢æŸ¥é€šé")
        except Exception as e:
            print(f"âš ï¸  æ¨¡å‹æª¢æŸ¥è­¦å‘Š: {e}")
            print("   ç¹¼çºŒä¿å­˜æ¨¡å‹...")
        
        # ä¿å­˜æ¨¡å‹
        print(f"ğŸ’¾ ä¿å­˜åˆ°: {output_file}")
        onnx.save(new_model, output_file)
        
        # é©—è­‰çµæœ
        print("\nğŸ§ª é©—è­‰çµæœ:")
        test_model = onnx.load(output_file)
        print(f"   æ–°opsetç‰ˆæœ¬: {[f'{op.domain}:{op.version}' for op in test_model.opset_import]}")
        
        new_size = os.path.getsize(output_file) / 1024 / 1024
        print(f"   æª”æ¡ˆå¤§å°: {new_size:.2f} MB")
        
        # æ¸¬è©¦èƒ½å¦ç”¨ONNX Runtimeè¼‰å…¥
        print("\nğŸ¯ æ¸¬è©¦ONNX Runtimeè¼‰å…¥...")
        try:
            import onnxruntime as ort
            session = ort.InferenceSession(output_file, providers=['CPUExecutionProvider'])
            print("âœ… ONNX RuntimeæˆåŠŸè¼‰å…¥æ¨¡å‹")
            
            # é¡¯ç¤ºè¼¸å…¥è¼¸å‡ºä¿¡æ¯
            print("   æ¨¡å‹è¼¸å…¥:")
            for inp in session.get_inputs():
                print(f"     {inp.name}: {inp.shape} ({inp.type})")
            print("   æ¨¡å‹è¼¸å‡º:")
            for out in session.get_outputs():
                print(f"     {out.name}: {out.shape} ({out.type})")
                
        except Exception as e:
            print(f"âŒ ONNX Runtimeè¼‰å…¥å¤±æ•—: {e}")
            return False
        
        print("\nâœ… æ¨¡å‹é‡å»ºå®Œæˆï¼")
        print(f"   è¼¸å‡ºæª”æ¡ˆ: {output_file}")
        return True
        
    except Exception as e:
        print(f"âŒ é‡å»ºå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = rebuild_model_with_opset12()
    if success:
        print("\nğŸ‰ æˆåŠŸï¼æ¨¡å‹å·²é‡å»ºç‚ºopset 12ç‰ˆæœ¬")
    else:
        print("\nğŸ’¥ å¤±æ•—ï¼è«‹æª¢æŸ¥éŒ¯èª¤ä¿¡æ¯")
