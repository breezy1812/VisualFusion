#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œå…¨é‡å»ºONNXæ¨¡å‹ï¼Œä½¿ç”¨opset 12å’ŒIR version 8ï¼Œç¢ºä¿èˆ‡ONNX Runtime 1.18.0å®Œå…¨å…¼å®¹
"""

import onnx
from onnx import TensorProto, helper, numpy_helper
import os
import numpy as np

def rebuild_model_compatible():
    """å®Œå…¨é‡å»ºæ¨¡å‹ï¼Œç¢ºä¿èˆ‡ONNX Runtime 1.18.0å®Œå…¨å…¼å®¹"""
    
    print("ğŸ”§ é‡å»ºå…¼å®¹æ¨¡å‹ - opset 12 + IR version 8")
    print("=" * 60)
    
    fp16_file = './SemLA_onnx_320x240_fp16_cuda.onnx'
    output_file = './SemLA_onnx_320x240_fp16_compatible.onnx'
    
    if not os.path.exists(fp16_file):
        print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {fp16_file}")
        return False
    
    try:
        # è¼‰å…¥åŸå§‹æ¨¡å‹
        print("ğŸ“ è¼‰å…¥åŸå§‹æ¨¡å‹...")
        original_model = onnx.load(fp16_file)
        original_graph = original_model.graph
        
        print(f"   åŸå§‹IRç‰ˆæœ¬: {original_model.ir_version}")
        print(f"   åŸå§‹opsetç‰ˆæœ¬: {[f'{op.domain}:{op.version}' for op in original_model.opset_import]}")
        
        # æ”¶é›†æ‰€æœ‰å¿…è¦çµ„ä»¶
        print("ğŸ“¦ æ”¶é›†æ¨¡å‹çµ„ä»¶...")
        
        # 1. æ”¶é›†åˆå§‹åŒ–å™¨ï¼ˆæ¬Šé‡ï¼‰
        initializers = []
        for init in original_graph.initializer:
            initializers.append(init)
        
        # 2. æ”¶é›†value_infoï¼ˆä¸­é–“å¼µé‡ä¿¡æ¯ï¼‰
        value_infos = []
        for vi in original_graph.value_info:
            value_infos.append(vi)
        
        # 3. æ”¶é›†ç¯€é»
        nodes = []
        for node in original_graph.node:
            nodes.append(node)
        
        print(f"   åˆå§‹åŒ–å™¨: {len(initializers)}, value_info: {len(value_infos)}, ç¯€é»: {len(nodes)}")
        
        # 4. é‡æ–°å‰µå»ºè¼¸å…¥å’Œè¼¸å‡º
        inputs = list(original_graph.input)
        outputs = list(original_graph.output)
        
        print("ğŸ—ï¸  é‡å»ºåœ–å½¢...")
        
        # å‰µå»ºæ–°åœ–å½¢
        new_graph = helper.make_graph(
            nodes=nodes,
            name="SemLA_compatible_graph",
            inputs=inputs,
            outputs=outputs,
            initializer=initializers,
            value_info=value_infos
        )
        
        # è¨­ç½®å…¼å®¹çš„opsetç‰ˆæœ¬
        opset_imports = [
            helper.make_opsetid("", 12)  # ä½¿ç”¨opset 12
        ]
        
        print("ğŸ“¦ é‡å»ºæ¨¡å‹...")
        
        # å‰µå»ºæ–°æ¨¡å‹ï¼Œæ˜ç¢ºè¨­ç½®IRç‰ˆæœ¬
        new_model = helper.make_model(
            new_graph, 
            opset_imports=opset_imports,
            producer_name="compatible_rebuild",
            producer_version="1.0"
        )
        
        # å¼·åˆ¶è¨­ç½®IRç‰ˆæœ¬ç‚º8ï¼ˆONNX Runtime 1.18.0å…¼å®¹ï¼‰
        new_model.ir_version = 8
        
        print("ğŸ” æª¢æŸ¥æ¨¡å‹...")
        
        # æª¢æŸ¥æ¨¡å‹
        try:
            onnx.checker.check_model(new_model)
            print("âœ… æ¨¡å‹æª¢æŸ¥é€šé")
        except Exception as e:
            print(f"âš ï¸  æ¨¡å‹æª¢æŸ¥è­¦å‘Š: {e}")
            print("   ç¹¼çºŒä¿å­˜æ¨¡å‹...")
        
        # ä¿å­˜æ¨¡å‹
        print(f"ğŸ’¾ ä¿å­˜åˆ°: {output_file}")
        onnx.save(new_model, output_file)
        
        # é©—è­‰çµæœ
        print("\nğŸ§ª é©—è­‰çµæœ:")
        test_model = onnx.load(output_file)
        print(f"   IRç‰ˆæœ¬: {test_model.ir_version}")
        print(f"   Opsetç‰ˆæœ¬: {[f'{op.domain}:{op.version}' for op in test_model.opset_import]}")
        
        new_size = os.path.getsize(output_file) / 1024 / 1024
        print(f"   æª”æ¡ˆå¤§å°: {new_size:.2f} MB")
        
        # æ¸¬è©¦èƒ½å¦ç”¨ONNX Runtimeè¼‰å…¥
        print("\nğŸ¯ æ¸¬è©¦ONNX Runtimeè¼‰å…¥...")
        try:
            import onnxruntime as ort
            session = ort.InferenceSession(output_file, providers=['CPUExecutionProvider'])
            print("âœ… ONNX RuntimeæˆåŠŸè¼‰å…¥æ¨¡å‹")
            
            # é¡¯ç¤ºè¼¸å…¥è¼¸å‡ºä¿¡æ¯
            print("   æ¨¡å‹è¼¸å…¥:")
            for inp in session.get_inputs():
                print(f"     {inp.name}: {inp.shape} ({inp.type})")
            print("   æ¨¡å‹è¼¸å‡º:")
            for out in session.get_outputs():
                print(f"     {out.name}: {out.shape} ({out.type})")
                
        except Exception as e:
            print(f"âŒ ONNX Runtimeè¼‰å…¥å¤±æ•—: {e}")
            return False
        
        print("\nâœ… æ¨¡å‹é‡å»ºå®Œæˆï¼")
        print(f"   è¼¸å‡ºæª”æ¡ˆ: {output_file}")
        return True
        
    except Exception as e:
        print(f"âŒ é‡å»ºå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = rebuild_model_compatible()
    if success:
        print("\nğŸ‰ æˆåŠŸï¼æ¨¡å‹å·²é‡å»ºç‚ºONNX Runtime 1.18.0å…¼å®¹ç‰ˆæœ¬")
        print("   å¯ä»¥æ›´æ–°config.jsonä½¿ç”¨æ–°æ¨¡å‹æª”æ¡ˆ")
    else:
        print("\nğŸ’¥ å¤±æ•—ï¼è«‹æª¢æŸ¥éŒ¯èª¤ä¿¡æ¯")
