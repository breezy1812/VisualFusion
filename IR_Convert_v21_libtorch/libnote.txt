
1. libtorch infTime need warmup
2. libtorch fp16 error: 
    * 精度不好：
        因為 libtorch 在真正的 fp16 上計算，不像是 pytorch 會利用模擬的方式，將誤差累計於 fp32 上。
        且因為 fp16 可以容許的誤差較少，所以才會使得整體精度降低。
    * 速度好：
        因為 libtorch 使用真正的 fp16 計算，不用模擬 fp32，所以減少轉換損耗。
3. onnx fp16：
    * 精度不準：
        推論策略與 libtorch 不同。
        每次推論 kernel 啟動時，thread 排程的順序不是保證 deterministic。
        因為 onnx 在執行過程中對於硬體調用能力較差，計算時因為，所以每次推論結果會有機率行出現錯誤（3%~5%）。

兩張圖eo ir算eo_homo_pred(矩陣) 
第一章影像的eo的點*eo_homo pred(矩陣) = kpts_pred(轉換後的點)
第一章影像的eo的點*homo_gt(自己建立的gt) = kpts_gt
kpts_p & kpts_gt計算所有特徵點計算距離差(MSE)