#include <core_image_align_libtorch.h>
#include "util_timer.h"
#include <fstream>
#include <chrono>
#include <iomanip>
#include <sstream>
#include <experimental/filesystem>

namespace core
{
  ImageAlign::ImageAlign(Param param) : param_(std::move(param))
  {
    torch::manual_seed(1);
    torch::autograd::GradMode::set_enabled(false);
    
    // ===== åŒæ­¥ Python ç«¯çš„ç¢ºå®šæ€§è¨­å®š =====
    // 1. é—œé–‰ TF32 (èˆ‡ Python torch.backends.cuda.matmul.allow_tf32 = False ç­‰åƒ¹)
    at::globalContext().setAllowTF32CuBLAS(false);
    at::globalContext().setAllowTF32CuDNN(false);
    // 2. å•Ÿç”¨ cuDNN deterministic (èˆ‡ Python torch.backends.cudnn.deterministic = True ç­‰åƒ¹)
    // at::globalContext().setDeterministicCuDNN(true);
    
    // 3. é—œé–‰ cuDNN benchmark (èˆ‡ Python torch.backends.cudnn.benchmark = False ç­‰åƒ¹)
    // at::globalContext().setBenchmarkCuDNN(false);
    
    // 4. è¨­å®š cuDNN ç‚ºç¢ºå®šæ€§æ¨¡å¼ (èˆ‡ Python torch.use_deterministic_algorithms(True) ç­‰åƒ¹)
    // at::globalContext().setDeterministicAlgorithms(true, false);

    printf("Deterministic settings applied:\n");
    printf("  - TF32 cuBLAS: disabled\n");
    printf("  - TF32 cuDNN: disabled\n");
    printf("  - cuDNN deterministic: enabled\n");
    printf("  - cuDNN benchmark: disabled\n");
    printf("  - Deterministic algorithms: enabled\n");

    if (param_.device.compare("cuda") == 0 && torch::cuda::is_available())
    {
      torch::Device cuda(torch::kCUDA);
      device = cuda;
    }

    // è¼‰å…¥ FP32 TorchScript æ¨¡å‹
    net = torch::jit::load(param_.model_path);
    net.eval();
    net.to(device);

    // â­ æ¥­ç•Œæ¨è–¦æ–¹æ¡ˆï¼šåœ¨ C++ ç«¯å‹•æ…‹è½‰æ›ç‚º FP16ï¼ˆè‹¥å•Ÿç”¨ï¼‰
    if (param_.mode.compare("fp16") == 0 && param_.device.compare("cuda") == 0) {
      printf("ğŸ”„ Converting FP32 model to FP16 (dynamic conversion in C++)...\n");
      
      // æ­¥é©Ÿ 1ï¼šæ•´é«”æ¨¡å‹è½‰æ›
      net.to(torch::kHalf);
      
      // æ­¥é©Ÿ 2ï¼šéæ­·æ‰€æœ‰å­æ¨¡çµ„ç¢ºä¿è½‰æˆåŠç²¾åº¦
      for (auto child : net.children()) {
        child.to(torch::kHalf);
      }
      
      // æ­¥é©Ÿ 3ï¼šéæ­·æ‰€æœ‰åƒæ•¸å¼·åˆ¶è½‰æˆåŠç²¾åº¦
      int param_count = 0;
      for (at::Tensor param : net.parameters()) {
        param.set_data(param.data().to(torch::kHalf));
        param_count++;
      }
      printf("  - Converted %d parameters to FP16\n", param_count);
      
      // æ­¥é©Ÿ 4ï¼šéæ­·æ‰€æœ‰ bufferï¼Œä½†ä¿æŒ BatchNorm çµ±è¨ˆç‚º FP32ï¼ˆé¿å…æ•¸å€¼ä¸ç©©å®šï¼‰
      int buffer_count = 0;
      int buffer_skipped = 0;
      for (at::Tensor buffer : net.buffers()) {
        // BatchNorm çš„ running_meanã€running_var ä¿æŒ FP32 ä»¥ç¶­æŒæ•¸å€¼ç©©å®šæ€§
        if (buffer.dtype() == torch::kFloat && buffer.numel() > 0) {
          // æª¢æŸ¥æ˜¯å¦ç‚º BatchNorm çµ±è¨ˆ bufferï¼ˆé€šå¸¸æ˜¯ 1D tensorï¼‰
          if (buffer.dim() == 1) {
            buffer_skipped++;
            continue;  // ä¿æŒ FP32
          }
        }
        buffer.set_data(buffer.data().to(torch::kHalf));
        buffer_count++;
      }
      printf("  - Converted %d buffers to FP16, kept %d buffers as FP32 (BatchNorm statistics)\n", 
             buffer_count, buffer_skipped);
      
      // ç¢ºä¿æ‰€æœ‰ CUDA ä»»å‹™å®Œæˆ
      if (torch::cuda::is_available()) {
        torch::cuda::synchronize();
      }
      
      printf("âœ… Model successfully converted to FP16 (mixed precision)\n");
      printf("  - Core layers: FP16 (Tensor Core acceleration)\n");
      printf("  - BatchNorm statistics: FP32 (numerical stability)\n");
      printf("  - Ready for inference\n");
    }

    printf("Model initialization completed\n");
    printf("  - Mode: %s\n", param_.mode.c_str());
    printf("  - Device: %s\n", param_.device.c_str());
    if (param_.mode.compare("fp16") == 0) {
      printf("  - Precision: FP16 (dynamically converted from FP32 model)\n");
    } else {
      printf("  - Precision: FP32\n");
    }

    // æ™ºèƒ½ warmup: åŸ·è¡Œ warmup ä¾†åˆå§‹åŒ– CUDA kernelsï¼Œä½†ä¸ä¿ç•™å…§éƒ¨ç‹€æ…‹
    if (param_.device.compare("cuda") == 0) {
      printf("Performing smart warmup to initialize CUDA kernels...\n");
      smart_warmup();
    }
  }

  void ImageAlign::smart_warmup()
  {
    printf("Smart warmup for CUDA kernel initialization (5 iterations)...\n");

    cv::Mat eo = cv::Mat::ones(param_.pred_height, param_.pred_width, CV_8UC1) * 128;
    cv::Mat ir = cv::Mat::ones(param_.pred_height, param_.pred_width, CV_8UC1) * 128;

    const auto t0 = std::chrono::high_resolution_clock::now();
    
    bool use_fp16 = (param_.mode.compare("fp16") == 0 && param_.device.compare("cuda") == 0);
    
    if (use_fp16) {
      printf("  - Warmup mode: FP16 (matching inference precision)\n");
    } else {
      printf("  - Warmup mode: FP32\n");
    }
    
    // åŸ·è¡Œ 5 æ¬¡æ¨ç†ä¾†å®Œå…¨åˆå§‹åŒ– CUDA kernels
    for (int i = 0; i < 5; i++) {
      printf("  Warmup iteration %d/5...\n", i + 1);
      
      torch::Tensor eo_tensor = torch::from_blob(eo.data, {1, 1, param_.pred_height, param_.pred_width}, torch::kUInt8).clone().to(device).to(torch::kFloat32) / 255.0f;
      torch::Tensor ir_tensor = torch::from_blob(ir.data, {1, 1, param_.pred_height, param_.pred_width}, torch::kUInt8).clone().to(device).to(torch::kFloat32) / 255.0f;
      
      // â­ æ¥­ç•Œæ¨è–¦ï¼šwarmup æ™‚è¼¸å…¥ç²¾åº¦èˆ‡æ¨è«–ä¸€è‡´
      if (use_fp16) {
        eo_tensor = eo_tensor.to(torch::kHalf);
        ir_tensor = ir_tensor.to(torch::kHalf);
      }
      
      // åŸ·è¡Œæ¨ç†ï¼ˆçµæœè¢«ä¸Ÿæ£„ï¼‰
      torch::IValue pred = net.forward({eo_tensor, ir_tensor});
    }

    const auto elapsed = std::chrono::high_resolution_clock::now() - t0;
    const double period = std::chrono::duration_cast<std::chrono::duration<double>>(elapsed).count();

    printf("Smart warmup completed in %.2f s (5 iterations)\n", period);
    printf("âœ… CUDA kernels initialized, ready for inference\n");
  }

  // prediction - OPTIMIZED: å„ªåŒ–æ•¸æ“šè™•ç†æµç¨‹ï¼Œæ¸›å°‘ CPU é–‹éŠ·
  // â­ æ¥­ç•Œæ¨è–¦æ–¹æ¡ˆï¼šæ¨¡å‹å·²åœ¨ C++ ç«¯è½‰ç‚º FP16ï¼Œè¼¸å…¥è³‡æ–™ä¹Ÿéœ€è½‰ç‚º FP16
  void ImageAlign::pred(cv::Mat &eo, cv::Mat &ir, std::vector<cv::Point2i> &eo_pts, std::vector<cv::Point2i> &ir_pts, const std::string& filename)
  {
    if (eo.channels() != 1 || ir.channels() != 1)
      throw std::runtime_error("ImageAlign::pred: eo and ir must be single channel images");

    // æ ¹æ“š pred_mode æ±ºå®šä½¿ç”¨ FP32 é‚„æ˜¯ FP16
    bool use_fp16 = (param_.mode.compare("fp16") == 0 && param_.device.compare("cuda") == 0);
    
    // è¨ˆæ™‚ - æ•¸æ“šæº–å‚™é–‹å§‹
    auto data_prep_start = std::chrono::high_resolution_clock::now();
    
    torch::Tensor eo_tensor, ir_tensor;
    
    // å„ªåŒ–ï¼šç›´æ¥åœ¨ GPU ä¸Šé€²è¡Œæ­¸ä¸€åŒ–ï¼Œæ¸›å°‘ CPU ç«¯çš„ convertTo é–‹éŠ·
    if (param_.device.compare("cuda") == 0) {
      // ç›´æ¥å¾ uint8 å‰µå»º tensor ä¸¦åœ¨ GPU ä¸Šæ­¸ä¸€åŒ–
      eo_tensor = torch::from_blob(eo.data, {1, 1, param_.pred_height, param_.pred_width}, torch::kUInt8)
                    .clone()  // å¿…é ˆ cloneï¼Œé¿å…æ•¸æ“šè¢«é‡‹æ”¾
                    .to(device)
                    .to(torch::kFloat32)
                    .div_(255.0f);  // åœ¨ GPU ä¸Šæ­¸ä¸€åŒ–ï¼Œä½¿ç”¨ inplace æ“ä½œæ›´å¿«
      
      ir_tensor = torch::from_blob(ir.data, {1, 1, param_.pred_height, param_.pred_width}, torch::kUInt8)
                    .clone()
                    .to(device)
                    .to(torch::kFloat32)
                    .div_(255.0f);
      
      // â­ æ¥­ç•Œæ¨è–¦ï¼šè¼¸å…¥è³‡æ–™å¿…é ˆèˆ‡æ¨¡å‹ç²¾åº¦ä¸€è‡´
      // è‹¥æ¨¡å‹å·²è½‰ FP16ï¼Œè¼¸å…¥ä¹Ÿè¦è½‰ FP16ï¼Œç¢ºä¿é¡å‹åŒ¹é…å’Œ Tensor Core åŠ é€Ÿ
      if (use_fp16) {
        eo_tensor = eo_tensor.to(torch::kHalf);
        ir_tensor = ir_tensor.to(torch::kHalf);
      }
    } else {
      // CPU æ¨¡å¼ï¼šåƒ…æ”¯æ´ FP32
      cv::Mat eo_float, ir_float;
      eo.convertTo(eo_float, CV_32F, 1.0 / 255.0, 0.0);
      ir.convertTo(ir_float, CV_32F, 1.0 / 255.0, 0.0);
      
      eo_tensor = torch::from_blob(eo_float.ptr<float>(), {1, 1, param_.pred_height, param_.pred_width}, torch::kFloat32).clone();
      ir_tensor = torch::from_blob(ir_float.ptr<float>(), {1, 1, param_.pred_height, param_.pred_width}, torch::kFloat32).clone();
    }
    
    auto data_prep_end = std::chrono::high_resolution_clock::now();
    double data_prep_time = std::chrono::duration_cast<std::chrono::microseconds>(data_prep_end - data_prep_start).count() / 1000.0; // ms
    
    // è¨ˆæ™‚ - æ¨¡å‹æ¨è«–é–‹å§‹
    auto model_inference_start = std::chrono::high_resolution_clock::now();

    // run the model
    torch::IValue pred = net.forward({eo_tensor, ir_tensor});
    
    // // ç¢ºä¿æ¨è«–å®Œæˆï¼ˆåƒ…åœ¨CUDAæ¨¡å¼ä¸‹ï¼‰
    // if (param_.device.compare("cuda") == 0) {
    //   torch::cuda::synchronize();
    // }
    
    // è¨ˆæ™‚ - æ¨¡å‹æ¨è«–çµæŸ
    auto model_inference_end = std::chrono::high_resolution_clock::now();
    double model_inference_time = std::chrono::duration_cast<std::chrono::microseconds>(model_inference_end - model_inference_start).count() / 1000000.0; // è½‰æ›ç‚ºç§’
    torch::jit::Stack pred_ = pred.toTuple()->elements();

    // æ–°æ¨¡å‹åªè¿”å› 2 å€‹è¼¸å‡ºï¼šmkpts0 å’Œ mkpts1 (int32 é¡å‹)
    torch::Tensor eo_mkpts = pred_[0].toTensor().to(torch::kInt32);
    torch::Tensor ir_mkpts = pred_[1].toTensor().to(torch::kInt32);

    // clean up eo_pts and ir_pts
    eo_pts.clear();
    ir_pts.clear();

    // éæ­·æ‰€æœ‰é»ï¼Œéæ¿¾æ‰åº§æ¨™ç‚º (0, 0) çš„ç„¡æ•ˆé»
    int num_points = eo_mkpts.size(0);  // ç²å–ç¸½é»æ•¸ï¼ˆæ‡‰è©²æ˜¯ 1200ï¼‰
    for (int i = 0; i < num_points; i++)
    {
      int eo_x = eo_mkpts[i][0].item<int>();
      int eo_y = eo_mkpts[i][1].item<int>();
      int ir_x = ir_mkpts[i][0].item<int>();
      int ir_y = ir_mkpts[i][1].item<int>();
      
      // è·³éåº§æ¨™ç‚º (0, 0) çš„ç„¡æ•ˆé»
      if (eo_x == 0 && eo_y == 0) {
        continue;
      }
      
      eo_pts.push_back(cv::Point2i(eo_x, eo_y));
      ir_pts.push_back(cv::Point2i(ir_x, ir_y));
    }
    
    int leng = eo_pts.size();  // å¯¦éš›æœ‰æ•ˆçš„ç‰¹å¾µé»æ•¸é‡
    
    // å¯«å…¥CSVæª”æ¡ˆ - åªè¨˜éŒ„æ¨¡å‹æ¨è«–æ™‚é–“
    writeTimingToCSV("Model_Inference", model_inference_time, leng, filename);
    
    // è¼¸å‡ºè©³ç´°è¨ˆæ™‚ä¿¡æ¯
    printf("â±ï¸  Timing breakdown:\n");
    printf("  - Data preparation: %.3f ms\n", data_prep_time);
    printf("  - Model inference: %.3f ms (%.6f s)\n", model_inference_time * 1000, model_inference_time);
    printf("  - Total: %.3f ms\n", data_prep_time + model_inference_time * 1000);

    // DEBUG: è¼¸å‡ºç‰¹å¾µé»æ•¸é‡
    std::cout << "  - Model extracted " << eo_pts.size() << " feature point pairs" << std::endl;
  }

  // align with last H - MODIFIED: ç°¡åŒ–éæ¿¾é‚è¼¯ï¼Œä½¿ç”¨Pythoné¢¨æ ¼çš„ç›´æ¥è¼¸å‡º
  void ImageAlign::align(cv::Mat &eo, cv::Mat &ir, std::vector<cv::Point2i> &eo_pts, std::vector<cv::Point2i> &ir_pts, cv::Mat &H, const std::string& filename)
  {
    // predict keypoints
    pred(eo, ir, eo_pts, ir_pts, filename);

    // CORRECTED: èˆ‡Pythonä»£ç¢¼å®Œå…¨ä¸€è‡´çš„ç‰¹å¾µé»ç¸®æ”¾æ¢ä»¶æª¢æŸ¥
    if (std::abs(param_.out_width_scale - 1.0) > 1e-6 || std::abs(param_.out_height_scale - 1.0) > 1e-6 || param_.bias_x > 0 || param_.bias_y > 0)
    {
      for (cv::Point2i &i : eo_pts)
      {
        i.x = i.x * param_.out_width_scale  ;
        i.y = i.y * param_.out_height_scale ;
      }
      for (cv::Point2i &i : ir_pts)
      {
        i.x = i.x * param_.out_width_scale  ;
        i.y = i.y * param_.out_height_scale ;
      }
      
      std::cout << "  - Feature point scaling applied: pred(" << param_.pred_width << "x" << param_.pred_height 
                << ") -> out(" << param_.out_width_scale * param_.pred_width << "x" << param_.out_height_scale * param_.pred_height 
                << "), scale=(" << param_.out_width_scale << ", " << param_.out_height_scale 
                << "), bias=(" << param_.bias_x << ", " << param_.bias_y << ")" << std::endl;
    }
    else
    {
      std::cout << "  - No feature point scaling needed: scale=(" << param_.out_width_scale << ", " << param_.out_height_scale 
                << "), bias=(" << param_.bias_x << ", " << param_.bias_y << ")" << std::endl;
    }
    
    // è¼¸å‡ºæœ€çµ‚ç‰¹å¾µé»æ•¸é‡
    std::cout << "  - Final feature points after coordinate adjustment: " << eo_pts.size() << std::endl;
  }

  // å¯«å…¥è¨ˆæ™‚è³‡æ–™åˆ°CSVæª”æ¡ˆ
  void ImageAlign::writeTimingToCSV(const std::string& operation, double time_ms, int leng, const std::string& filename)
  {
    std::string csv_filename = "./itiming_log.csv";
    bool file_exists = std::experimental::filesystem::exists(csv_filename);
    
    std::ofstream csv_file(csv_filename, std::ios::app);
    
    if (!file_exists) {
      // å¯«å…¥CSVæ¨™é ­
      csv_file << "Filename,Operation,Time_s,Mode,keypoints\n";
    }
    
    // ä½¿ç”¨æª”æ¡ˆåç¨±ä»£æ›¿æ™‚é–“æˆ³ï¼Œå¦‚æœæ²’æœ‰æä¾›æª”æ¡ˆåç¨±å‰‡ä½¿ç”¨æ™‚é–“æˆ³
    std::string identifier;
    if (!filename.empty()) {
      identifier = filename;
    } else {
      std::cout<<"warm up"<<std::endl;
      return;
    }
    
    // å¯«å…¥è³‡æ–™
    csv_file << identifier << "," 
             << operation << "," 
             << std::fixed << std::setprecision(6) << time_ms << ","
             << param_.mode << ","
             << leng << "\n";
    
    csv_file.close();
  }
} /* namespace core */
