import os
import torch
import numpy as np
import random
from model_jit.SemLA import SemLA

# ============================================================================
# ğŸ”’ è¨­ç½®å®Œå…¨ç¢ºå®šæ€§
# ============================================================================
def set_all_seeds(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    # cuDNN è¨­ç½®
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    if hasattr(torch.backends.cuda, 'matmul'):
        torch.backends.cuda.matmul.allow_tf32 = False
    if hasattr(torch.backends.cudnn, 'allow_tf32'):
        torch.backends.cudnn.allow_tf32 = False
    try:
        torch.use_deterministic_algorithms(True)
    except Exception:
        os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'
    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'
    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
    print(f"âœ… Seeds set to {seed}, deterministic mode enabled")

# ============================================================================
# ä¸»è¦æµç¨‹
# ============================================================================
def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    fpMode = torch.float32

    # è¨­ç½®éš¨æ©Ÿç¨®å­
    set_all_seeds(42)
    torch.set_grad_enabled(False)

    # -------------------- è¼‰å…¥æ¨¡å‹ --------------------
    print("æ­£åœ¨è¼‰å…¥åŸå§‹æ¨¡å‹...")
    matcher = SemLA(device=device, fp=fpMode)
    matcher.load_state_dict(torch.load("./reg.ckpt", map_location=device), strict=False)
    matcher.eval()
    matcher = matcher.to(device, dtype=fpMode)

    # é©—è­‰ BatchNorm å±¤
    print("ğŸ” é©—è­‰ BatchNorm å±¤...")
    bn_count = 0
    for name, module in matcher.named_modules():
        if isinstance(module, torch.nn.BatchNorm2d):
            bn_count += 1
            module.eval()
    print(f"âœ… æ‰¾åˆ° {bn_count} å€‹ BatchNorm2d å±¤ï¼Œå…¨éƒ¨å·²è¨­ç½®ç‚º eval æ¨¡å¼")

    # -------------------- dummy forward åˆå§‹åŒ– --------------------
    set_all_seeds(42)
    dummy_input_rgb = torch.randn(1, 1, 240, 320, device=device, dtype=fpMode)
    dummy_input_ir  = torch.randn(1, 1, 240, 320, device=device, dtype=fpMode)
    with torch.no_grad():
        _ = matcher(dummy_input_rgb, dummy_input_ir)
    print("âœ… dummy forward å®Œæˆï¼Œæ¨¡å‹ buffer å·²åˆå§‹åŒ–")

    # -------------------- çœŸå¯¦åœ–ç‰‡ forward æ¸¬è©¦ --------------------
    print("\n=== çœŸå¯¦åœ–ç‰‡æ¸¬è©¦ ===")
    # å‡è¨­ä½ æœ‰çœŸå¯¦åœ–ç‰‡ tensor: rgb_img, ir_img
    # é€™è£¡ç”¨éš¨æ©Ÿ tensor æ¨¡æ“¬
    rgb_img = torch.randn(1, 1, 240, 320, device=device, dtype=fpMode)
    ir_img  = torch.randn(1, 1, 240, 320, device=device, dtype=fpMode)

    with torch.no_grad():
        output_real = matcher(rgb_img, ir_img)
    print("âœ… çœŸå¯¦åœ–ç‰‡ forward å®Œæˆï¼Œè¼¸å‡ºå½¢ç‹€:")
    # for i, o in enumerate(output_real):
    #     print(f"  output[{i}]: {o.shape}")

    # -------------------- ä¿å­˜ TorchScript æ¨¡å‹ --------------------
    print("\n=== è½‰æ› TorchScript æ¨¡å‹ ===")
    set_all_seeds(42)
    matcher_scripted = torch.jit.script(matcher)
    output_path = "/circ330/forgithub/VisualFusion_libtorch/IR_Convert_v21_libtorch/model/SemLA_fp32.zip"
    torch.jit.save(matcher_scripted, output_path)
    print(f"âœ… TorchScript æ¨¡å‹å·²ä¿å­˜åˆ°: {output_path}")

#     # -------------------- é©—è­‰ TorchScript èˆ‡åŸå§‹æ¨¡å‹ä¸€è‡´æ€§ --------------------
#     print("\n=== é©—è­‰ TorchScript æ¨¡å‹ ===")
#     loaded_model = torch.jit.load(output_path, map_location=device)
#     loaded_model.eval()

#     set_all_seeds(42)
#     test_input_rgb = torch.randn(1, 1, 240, 320, device=device, dtype=fpMode)
#     test_input_ir  = torch.randn(1, 1, 240, 320, device=device, dtype=fpMode)

#     with torch.no_grad():
#         orig_out = matcher(test_input_rgb, test_input_ir)
#         js_out   = loaded_model(test_input_rgb, test_input_ir)

#     print("\nğŸ“Š æ•¸å€¼ä¸€è‡´æ€§é©—è­‰:")
#     for i, (o, j) in enumerate(zip(orig_out, js_out)):
#         max_diff = torch.max(torch.abs(o - j)).item()
#         mean_diff = torch.mean(torch.abs(o - j)).item()
#         is_close = torch.allclose(o, j, atol=1e-6, rtol=1e-5)
#         status = "âœ… é€šé" if is_close else "âš ï¸ æœ‰å·®ç•°"
#         print(f"output[{i}]: {status}, max diff: {max_diff:.2e}, mean diff: {mean_diff:.2e}")

#     print("\nâœ… å…¨éƒ¨å®Œæˆï¼æ¨¡å‹å¯ç›´æ¥åœ¨ libtorch C++ ä½¿ç”¨")

# # ============================================================================
if __name__ == "__main__":
    main()
