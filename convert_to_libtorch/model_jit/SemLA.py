import torch
import torch.nn as nn
import torch.nn.functional as F
from .reg import SemLA_Reg
from .utils import n_c_h_w_2_n_hw_c
torch.set_printoptions(sci_mode=False)

class SemLA(nn.Module):

    def __init__(self, device, fp=torch.float32):
        super().__init__()
        self.backbone = SemLA_Reg(device, fp)
        
    def forward(self, img_vi, img_ir):
        # ===== ğŸ”§ TensorRT 8.4 å®Œå…¨ç›¸å®¹ç‰ˆæœ¬ï¼šç§»é™¤æ‰€æœ‰ä¸æ”¯æ´çš„é‹ç®—ç¬¦ =====
        # ä¸æ”¯æ´: NonZero, Mod, Where, å‹•æ…‹ç´¢å¼•
        # ç­–ç•¥ï¼šä½¿ç”¨å›ºå®šå½¢ç‹€ï¼Œå®Œå…¨éœæ…‹çš„æ“ä½œ
        
        feat_reg_vi_final, feat_reg_ir_final, feat_sa_vi, feat_sa_ir = self.backbone(
            torch.cat((img_vi, img_ir), dim=0)
        )
        
        # å›ºå®šå°ºå¯¸å¸¸æ•¸
        batch_size = 1
        height = 30  # 240 / 8
        width = 40   # 320 / 8
        fixed_num_points = 1200  # å›ºå®šè¼¸å‡º 1200 å€‹ç‰¹å¾µé»
        
        # ä½¿ç”¨æ‰€æœ‰ç‰¹å¾µé»ï¼ˆä¸åšé–¾å€¼ç¯©é¸ï¼Œé¿å… NonZeroï¼‰
        # feat_reg_vi/ir: [1, 1200, 256]
        feat_reg_vi = n_c_h_w_2_n_hw_c(feat_reg_vi_final)
        feat_reg_ir = n_c_h_w_2_n_hw_c(feat_reg_ir_final)
        
        # æ­£è¦åŒ–
        feat_reg_vi = feat_reg_vi / (feat_reg_vi.shape[-1] ** 0.5)
        feat_reg_ir = feat_reg_ir / (feat_reg_ir.shape[-1] ** 0.5)
        
        # è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£ [1, 1200, 1200]
        conf = torch.einsum("nlc,nsc->nls", feat_reg_vi, feat_reg_ir) / 0.1
        
        # æ‰¾åˆ°æ¯å€‹ vi ç‰¹å¾µå°æ‡‰çš„æœ€ä½³ ir ç‰¹å¾µï¼ˆé¿å… whereï¼‰
        conf_max_val, conf_max_idx = conf.max(dim=2)  # [1, 1200]
        
        # é›™å‘æœ€å¤§å€¼æª¢æŸ¥ï¼ˆmutual nearest neighborï¼‰
        # é¿å…ä½¿ç”¨ whereï¼Œæ”¹ç”¨ max + æ¯”è¼ƒ
        mask_forward = (conf == conf.max(dim=2, keepdim=True)[0]).float()
        mask_backward = (conf == conf.max(dim=1, keepdim=True)[0]).float()
        mask_mutual = mask_forward * mask_backward  # [1, 1200, 1200]
        
        # å–å¾—æ¯å€‹ vi é»çš„æœ€ä½³åŒ¹é… ir é»ç´¢å¼•
        _, j_ids_all = mask_mutual.max(dim=2)  # [1, 1200]
        
        # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„åº§æ¨™ï¼ˆé¿å…ä½¿ç”¨ % å’Œå‹•æ…‹ç´¢å¼•ï¼‰
        # ä½¿ç”¨å®Œå…¨éœæ…‹çš„åº§æ¨™ç”Ÿæˆ
        y_coords = torch.arange(height, device=img_vi.device).view(-1, 1).repeat(1, width).view(-1)
        x_coords = torch.arange(width, device=img_vi.device).view(1, -1).repeat(height, 1).view(-1)
        
        # mkpts0: vi çš„åº§æ¨™ [1200, 2]
        mkpts0 = torch.stack([x_coords, y_coords], dim=1).float() * 8.0
        
        # mkpts1: æ ¹æ“š j_ids_all å–å¾—å°æ‡‰çš„ ir åº§æ¨™
        j_ids = j_ids_all[0]  # [1200]
        
        # é¿å…ä½¿ç”¨ % é‹ç®—ç¬¦ï¼Œæ”¹ç”¨é™¤æ³•å’Œæ¸›æ³•
        j_y = j_ids // width  # æ•´æ•¸é™¤æ³•
        j_x = j_ids - j_y * width  # æ›¿ä»£ j_ids % width
        mkpts1 = torch.stack([j_x.float(), j_y.float()], dim=1) * 8.0
        
        # è¿”å›å›ºå®šå¤§å°çš„è¼¸å‡º [1200, 2]
        # è¨ˆç®—å¯¦éš›æœ‰æ•ˆçš„åŒ¹é…é»æ•¸é‡ï¼ˆåŸºæ–¼ mutual maskï¼‰
        # mask_mutual: [1, 1200, 1200]
        # ä¸ä½¿ç”¨ squeezeï¼Œç›´æ¥ç´¢å¼•å–å¾— [1200] çš„ tensor
        mask_valid = mask_mutual.sum(dim=2)[0]  # ç›´æ¥ç´¢å¼•å– batch 0ï¼Œé¿å… squeeze ç”¢ç”Ÿ If ç¯€é»
        mask_valid = (mask_valid > 0).float()  # è½‰æ›ç‚º 0/1 maskï¼Œshape: [1200]
        
        # å°‡ç„¡æ•ˆé»çš„åº§æ¨™è¨­ç‚º (0, 0)
        # mask_valid: [1200]ï¼Œ1 è¡¨ç¤ºæœ‰æ•ˆï¼Œ0 è¡¨ç¤ºç„¡æ•ˆ
        mkpts0_final = mkpts0 * mask_valid.unsqueeze(1)  # [1200, 2]
        mkpts1_final = mkpts1 * mask_valid.unsqueeze(1)  # [1200, 2]
        
        # âš ï¸ é‡è¦ï¼šè½‰æ›ç‚º int32ï¼Œèˆ‡ C++ ä»£ç¢¼åŒ¹é…
        # C++ æœŸæœ› int32_t é¡å‹çš„åº§æ¨™
        mkpts0_final = mkpts0_final.to(torch.int32)
        mkpts1_final = mkpts1_final.to(torch.int32)
        
        # å›ºå®šè¼¸å‡º 1200 å€‹é»
        # C++ ä»£ç¢¼éœ€è¦éæ­·æ‰€æœ‰é»ï¼Œè·³éåº§æ¨™ç‚º (0, 0) çš„é»
        return mkpts0_final, mkpts1_final
