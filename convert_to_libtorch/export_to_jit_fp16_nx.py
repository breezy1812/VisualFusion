import os
import torch
import numpy as np
import random
from model_jit.SemLA import SemLA

# ============================================================================
# ğŸ”’ è¨­ç½®å®Œå…¨ç¢ºå®šæ€§ï¼ˆFP16 æ¨¡å¼ï¼‰
# ============================================================================
def set_all_seeds(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    
    # cuDNN è¨­ç½®ï¼šç¢ºå®šæ€§æ¨¡å¼
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    print("âœ… cuDNN deterministic mode enabled")
    
    # ç¦ç”¨ TF32ï¼ˆRTX 30 ç³»åˆ—çš„é—œéµè¨­ç½®ï¼‰
    if hasattr(torch.backends.cuda, 'matmul'):
        torch.backends.cuda.matmul.allow_tf32 = False
        print("âœ… CUDA matmul TF32 disabled")
    
    if hasattr(torch.backends.cudnn, 'allow_tf32'):
        torch.backends.cudnn.allow_tf32 = False
        print("âœ… cuDNN TF32 disabled")
    
    # è¨­ç½®ç’°å¢ƒè®Šé‡ï¼Œå¼·åˆ¶ç¦ç”¨ TF32
    os.environ['NVIDIA_TF32_OVERRIDE'] = '0'
    print("âœ… NVIDIA_TF32_OVERRIDE = 0")
    
    # ç¢ºå®šæ€§ç®—æ³•
    try:
        torch.use_deterministic_algorithms(True)
        print("âœ… Deterministic algorithms enabled")
    except Exception:
        os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'
        print("âš ï¸  Fallback to CUBLAS_WORKSPACE_CONFIG")
    
    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'
    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
    
    print(f"âœ… Seeds set to {seed}, FP16 MODE ENABLED")
    print("   - TF32: DISABLED")
    print("   - FP16: ENFORCED")

# ============================================================================
# ä¸»è¦æµç¨‹ï¼šPyFP16 â†’ LibTorch FP16ï¼ˆç›´æ¥å°å‡º FP16ï¼‰
# ============================================================================
def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    
    # è¨­ç½®éš¨æ©Ÿç¨®å­ï¼ˆFP16 æ¨¡å¼ï¼‰
    set_all_seeds(42)
    torch.set_grad_enabled(False)

    matcher = SemLA(device=device, fp=torch.float16)
    matcher.load_state_dict(torch.load("./reg.ckpt", map_location=device), strict=False)
    matcher.eval()
    matcher = matcher.to(device, dtype=torch.float16)
    
    
    # dummy forward åˆå§‹åŒ–ï¼ˆFP16ï¼‰
    dummy_input_rgb = torch.randn(1, 1, 240, 320, device=device, dtype=torch.float16)
    dummy_input_ir  = torch.randn(1, 1, 240, 320, device=device, dtype=torch.float16)
    with torch.no_grad():
        _ = matcher(dummy_input_rgb, dummy_input_ir)
    print("âœ… dummy forward å®Œæˆï¼Œæ¨¡å‹ buffer å·²åˆå§‹åŒ–ï¼ˆFP16ï¼‰")
    
    # è½‰æ›ç‚º TorchScript
    matcher_scripted_fp16 = torch.jit.script(matcher)
    fp16_output_path = "../IR_Convert_v21_libtorch_nx/model/nx_SemLA_fp16.zip"
    torch.jit.save(matcher_scripted_fp16, fp16_output_path)
    print(f"âœ… LibTorch FP16 æ¨¡å‹å·²ä¿å­˜åˆ°: {fp16_output_path}")

if __name__ == "__main__":
    main()
